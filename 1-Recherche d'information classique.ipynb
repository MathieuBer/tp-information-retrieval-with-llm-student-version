{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathieuBer/tp-information-retrieval-with-llm-student-version/blob/main/1-Recherche%20d'information%20classique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugX7FayQ90_A"
      },
      "source": [
        "# Partie 1. - Recherche d'Information classique\n",
        "\n",
        "Dans cette partie, nous allons mettre en oeuvre des principes et modèles classiques de Recherche d'Information. Le jeu de donnée est une collection de livres au format texte (.txt) de Henry Rider Haggard. Jetez un oeil à ces documents dans le dossier _data_.\n",
        "\n",
        "En sortie de ce module, vous serez capable de :\n",
        "\n",
        "- Construire un index inversé ;\n",
        "- Effectuer des requêtes simples selon le modèle booléen :\n",
        "- Calculer la pondération des termes selon la méthode TF-IDF ;\n",
        "- Mettre en oeuvre le modèle vectoriel de recherche d'information et y appliquer des requêtes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw1BGZgY-tvZ"
      },
      "source": [
        "### Import des bibliothèques logicielles et configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les lignes suivantes permettent d'instancier un objet la classe `IRSystem` représentant notre moteur de recherche et de charger les données en RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pas sur Google Colab, ces commandes ne seront pas exécutées.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Vérifie si le code est exécuté sur Google Colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    # Commandes à exécuter uniquement sur Google Colab\n",
        "    !git clone https://github.com/vincentmartin/tp-information-retrieval-with-llm-student-version.git\n",
        "    %cd tp-information-retrieval-with-llm-student-version\n",
        "else:\n",
        "    # Commandes à exécuter si ce n'est pas sur Google Colab\n",
        "    print(\"Pas sur Google Colab, ces commandes ne seront pas exécutées.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chargement des données\n",
        "\n",
        "Les lignes ci-dessous permettent de charger les données qui sont un ensemble de 60 livres au format texte (.txt) d'[Henry Rider Haggard ](https://fr.wikipedia.org/wiki/Henry_Rider_Haggard).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZNWPECSs9wgH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading in documents...\n",
            "Already stemmed!\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "There are not 60 documents in ./data/RiderHaggard/stemmed/\nRemove ./data/RiderHaggard/stemmed/ directory and re-run.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mathi\\Desktop\\tp-information-retrieval-with-llm-student-version\\1-Recherche d'information classique.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# !rm -rf ./data/RiderHaggard/stemmed\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ir_system \u001b[39m=\u001b[39m IRSystem()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ir_system\u001b[39m.\u001b[39;49mread_data(\u001b[39m'\u001b[39;49m\u001b[39m./data/RiderHaggard\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# chargement des données et prétraitement des documents (stemming).\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mathi\\Desktop\\tp-information-retrieval-with-llm-student-version\\classic_ir\\IRSystem.py:104\u001b[0m, in \u001b[0;36mIRSystem.read_data\u001b[1;34m(self, dirname)\u001b[0m\n\u001b[0;32m    102\u001b[0m subdirs \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(dirname)\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstemmed\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m subdirs:\n\u001b[1;32m--> 104\u001b[0m     titles, docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__read_stemmed_data(dirname)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     titles, docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__read_raw_data(dirname)\n",
            "File \u001b[1;32mc:\\Users\\mathi\\Desktop\\tp-information-retrieval-with-llm-student-version\\classic_ir\\IRSystem.py:77\u001b[0m, in \u001b[0;36mIRSystem.__read_stemmed_data\u001b[1;34m(self, dirname)\u001b[0m\n\u001b[0;32m     75\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThere are not 60 documents in ./data/RiderHaggard/stemmed/\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRemove ./data/RiderHaggard/stemmed/ directory and re-run.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(msg)\n\u001b[0;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m i, filename \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(filenames):\n\u001b[0;32m     80\u001b[0m     title \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n",
            "\u001b[1;31mException\u001b[0m: There are not 60 documents in ./data/RiderHaggard/stemmed/\nRemove ./data/RiderHaggard/stemmed/ directory and re-run."
          ]
        }
      ],
      "source": [
        "from classic_ir.IRSystem import *\n",
        "\n",
        "# !rm -rf ./data/RiderHaggard/stemmed\n",
        "ir_system = IRSystem()\n",
        "ir_system.read_data('./data/RiderHaggard') # chargement des données et prétraitement des documents (stemming)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 1. - Construction de l'index inversé\n",
        "\n",
        "Ce premier exercice a pour objectif de construire l'index inversé non positionnel. L'attribut `self.inverted_index` est un tableau associatif qui associe une liste d'entiers (docIDs) à un mot (word).\n",
        " \n",
        "Documentation ici https://docs.python.org/3/library/collections.html#collections.defaultdict. \n",
        "\n",
        "Exercice : modifier la fonction `index` pour calculer l'index inversé. \n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Inverted Index Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'IRSystem' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mathi\\Desktop\\tp-information-retrieval-with-llm-student-version\\1-Recherche d'information classique.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverted_index \u001b[39m=\u001b[39m inverted_index\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Ne pas modifier les lignes ci-dessous\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m IRSystem\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m index\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m ir_system\u001b[39m.\u001b[39mindex()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/tp-information-retrieval-with-llm-student-version/1-Recherche%20d%27information%20classique.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m run_tests(ir_system, part\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'IRSystem' is not defined"
          ]
        }
      ],
      "source": [
        "# Exercice 1. Indexation\n",
        "\n",
        "def index(self):\n",
        "    \"\"\"\n",
        "    Construit l'index inversé et le stocke dans self.inverted_index.\n",
        "\n",
        "    Dans le code ci-dessous, seul le dictionnaire des tokens est construit. Les postings lists sont vides.\n",
        "    \"\"\"\n",
        "    print(\"Indexing...\")\n",
        "    self.tf = defaultdict(Counter) # tf est un dictionnaire qui à un document associe un Counter de mots.\n",
        "    inverted_index = defaultdict(list) # inverted_index est un dictionnaire qui à un mot associe une liste de documents. \n",
        "    for word in self.vocab:\n",
        "        for doc in self.docs:\n",
        "            if word in self.docs[doc]:\n",
        "                self.tf[doc][word] = self.docs[doc][word]\n",
        "                if doc not in inverted_index[word]:\n",
        "                    inverted_index[word].append(doc)\n",
        "\n",
        "    self.inverted_index = inverted_index\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.index = index\n",
        "ir_system.index()\n",
        "run_tests(ir_system, part=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 2. - Recherche booléenne\n",
        "\n",
        "Ce deuxième exercice a pour objectif d'implémenter la recherche booléenne. La requête `query` est une liste de mots _lemmatisés_ et l'algorithme doit rechercher les documents qui contiennent TOUS ces mots. \n",
        "\n",
        "\n",
        "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Boolean Retrieval Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercice 2. Recherche booléenne\n",
        "def boolean_retrieve(self, query):\n",
        "    \"\"\"\n",
        "    A partir d'une requête sous la forme d'une liste de mots *lemmatisés*,\n",
        "    retourne la liste des documents dans lesquels *tous* ces mots apparaissent (ie une requête AND).\n",
        "    Retourne une liste vide si la requête ne retourne aucun document.\n",
        "\n",
        "    Dans le code ci-dessous, tous les documents répondent.\n",
        "    \"\"\"\n",
        "    docs = list()\n",
        "    for doc in self.docs:\n",
        "        docs.append(doc)\n",
        "    return docs\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.boolean_retrieve = boolean_retrieve\n",
        "run_tests(ir_system, part=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 3. - Calcul des poids TF-IDF des termes dans les documents\n",
        "\n",
        "Dans ce troisième exercice, l'objectif est de pré-calculer les poids TF-IDF pour chaque terme dans chaque document. Pour ce faire, appliquer la formule vue en cours. Utiliser le logarithme en base 10.\n",
        "\n",
        "\n",
        "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "Calculating tf-idf...\n",
        "===== Running tests =====\n",
        "TF-IDF Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercice 3. calcul des scores tf-idf\n",
        "def compute_tfidf(self):\n",
        "    \"\"\"\n",
        "    Calcule les scores tf-idf pour tous les mots de tous les documents et les stocke dans self.tfidf.\n",
        "\n",
        "    Dans le code ci-dessous, les scores tf-idf sont tous nuls.\n",
        "    \"\"\"\n",
        "    print(\"Calculating tf-idf...\")\n",
        "    \n",
        "    self.tfidf = defaultdict(Counter)\n",
        "    N = len(self.docs)  # N = nombre de documents\n",
        "    for word in self.vocab:\n",
        "        for i in range(N):\n",
        "            try:\n",
        "                self.tfidf[i][word] = 0.\n",
        "            except ValueError:\n",
        "                self.tfidf[i][word] = 0.\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.compute_tfidf = compute_tfidf\n",
        "ir_system.compute_tfidf()\n",
        "run_tests(ir_system, part=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice 4. - Calcul de la similarité cosinus.\n",
        "\n",
        "Dans ce troisième exercice, l'objectif est de pré-calculer les poids TF-IDF pour chaque terme dans chaque document. Pour ce faire, appliquer la formule vue en cours en considérant les éléments suivants :\n",
        "- Ne considérer que la mesure TF pour calculer le poids des termes de la requête (on utilise pas IDF).\n",
        "- utiliser le logarithme en base 10. \n",
        "\n",
        "Exercice : modifier la fonction `rank_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Cosine Similarity Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercice 4. Similarité cosinus\n",
        "def rank_retrieve(self, query):\n",
        "    \"\"\"\n",
        "    A partir d'une requête (une liste de mots), retourne une liste de documents (classés par docID) et de scores pour la requête en appliquant la simalirité cosinus.\n",
        "\n",
        "    Dans l'exemple ci-dessous. C'est la mesure de Jaccard qui est utilisée.\n",
        "    \"\"\"\n",
        "    scores = [0.0 for _ in range(len(self.docs))]\n",
        "\n",
        "    query_set = set(query)\n",
        "    \n",
        "    for d in range(len(self.docs)):\n",
        "        doc_set = set(self.docs[d])\n",
        "        intersection = len(query_set & doc_set)\n",
        "        union = len(query_set | doc_set)\n",
        "        # Calcul de la similarité Jaccard\n",
        "        scores[d] = intersection / union if union != 0 else 0.0\n",
        "\n",
        "    # Tri des scores\n",
        "    ranking = [idx for idx, sim in sorted(enumerate(scores),\n",
        "                                        key=lambda pair: pair[1], reverse=True)]\n",
        "    results = []\n",
        "    for i in range(10):\n",
        "        results.append((ranking[i], scores[ranking[i]]))\n",
        "    return results\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.rank_retrieve = rank_retrieve\n",
        "run_tests(ir_system, part=3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNKktqd75RwDFlI5Cdrd/bs",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
